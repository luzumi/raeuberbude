{
  "project": {
    "id": "LUD28"
  },
  "summary": "Speech Input Dashboard Integration - Spracheingabe mit Rechteverwaltung",
  "description": "# Speech Input Dashboard Integration\n\n## Beschreibung\nImplementierung einer Spracheingabe-Funktion im Räuberbude Smart Home Dashboard mit persistenter Speicherung, Rechteverwaltung und visueller Rückmeldung im Header.\n\n## Anforderungen\n\n### Funktionale Anforderungen\n- **Speech Input Button**: Zentraler App-Button im Header, der die Spracheingabe startet\n- **Auto-Stop**: Aufnahme stoppt automatisch nach definierter Zeit oder Sprachende\n- **Persistenz**: Erkannte Eingabe wird als 'human_input' in der Datenbank gespeichert\n- **Kontext-Daten**: Zu jeder Eingabe werden User, Zeitstempel und App-Terminal-ID erfasst\n- **Visuelles Feedback**: Lauftext der letzten Eingabe im Header anzeigen\n\n### Datenmodell-Erweiterungen\n- User-Entity mit Rollen und Berechtigungen\n- App-Terminal-Entity für Geräteverwaltung\n- Rights-Entity für granulare Rechteverwaltung\n- Human-Input-Entity mit Relationen zu User und Terminal\n\n### Rechtesystem\n- Rollenbasierte Zugriffskontrolle (RBAC)\n- Rollen: Admin, Regular User, Guest, Terminal\n- Management-GUI zur Rechteverwaltung (via Dashboard-Menü)\n- Terminal-spezifische Berechtigungen\n\n### Technische Anforderungen\n- **Performance**: Ladezeit unter 2 Sekunden\n- **Security**: Authentifizierung erforderlich\n- **Integration**: HomeAssistant-Kompatibilität beibehalten\n- **Monitoring**: Logging aller Aktionen\n\n## Acceptance Criteria\n\n### AC1: Speech Input Trigger\n- [ ] App-Button ist im Header sichtbar\n- [ ] Button startet Mikrofon-Aufnahme bei Klick\n- [ ] Visuelles Feedback während Aufnahme (Animation)\n- [ ] Automatischer Stop nach Timeout oder Stille\n\n### AC2: Datenbankintegration\n- [ ] Collection 'human_input' erstellt\n- [ ] Felder: userId, terminalId, timestamp, inputText, context\n- [ ] Daten werden korrekt gespeichert und verknüpft\n- [ ] Einträge im Admin Panel einsehbar\n\n### AC3: Rechteverwaltung\n- [ ] RBAC-Modell implementiert\n- [ ] GUI für Rechteverwaltung funktionsfähig\n- [ ] Rechte-Middleware in API integriert\n- [ ] Änderungen sofort wirksam\n\n### AC4: UI-Feedback\n- [ ] Lauftext zeigt letzte Eingabe im Header\n- [ ] Text scrollt horizontal bei Überlänge\n- [ ] Styling konsistent mit Dashboard-Theme\n- [ ] Neue Eingabe ersetzt vorherige\n\n## User Stories\n\n### SPEECH-001: Speech Input Button\n**Als** Benutzer  \n**möchte ich** einen Button im Header haben  \n**damit** ich Sprachbefehle eingeben kann  \n\n### SPEECH-002: Input Logging\n**Als** Administrator  \n**möchte ich** alle Spracheingaben protokolliert sehen  \n**damit** ich die Nutzung nachvollziehen kann  \n\n### SPEECH-003: Rechteverwaltung\n**Als** Administrator  \n**möchte ich** Benutzerrechte verwalten können  \n**damit** ich den Zugriff auf Funktionen steuern kann  \n\n### SPEECH-004: Visual Feedback\n**Als** Benutzer  \n**möchte ich** meine Eingabe im Header sehen  \n**damit** ich weiß, was erkannt wurde  \n\n## Tasks\n\n### Phase 1: Design & Architektur (3 Tage)\n1. Datenmodell entwerfen (User, Terminal, Rights, HumanInput)\n2. API-Endpunkte spezifizieren\n3. UI/UX-Mockups erstellen\n4. Datenfluss-Architektur definieren\n\n### Phase 2: Backend (5 Tage)\n1. NestJS Speech Input API implementieren\n2. MongoDB Schema erweitern\n3. Human Input Logging entwickeln\n4. Rechte-Middleware erstellen\n\n### Phase 3: Frontend (4 Tage)\n1. Header-Button Komponente entwickeln\n2. Lauftext-Komponente implementieren\n3. Rechte-GUI erstellen\n4. Web Speech API integrieren\n\n### Phase 4: Testing & QA (2 Tage)\n1. Unit & Integration Tests\n2. Rechtesystem Tests\n3. Performance Tests\n4. E2E Tests mit verschiedenen Browsern",
  "customFields": {
    "Type": { "name": "Feature" },
    "Priority": { "name": "Critical" },
    "State": { "name": "Open" }
  }
}
