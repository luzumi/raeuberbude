# LLM Load/Eject Testing Guide

## Quick Start

### 1. Backend starten

```bash
cd backend/nest-app
npm start
```

Der MCP Server wird automatisch gestartet und sollte folgende Logs zeigen:
```
[LmStudioMcpService] Starting LM Studio MCP Server: .specify/mcp-servers/lm-studio-mcp-server.js
[LmStudioMcpService] LM Studio MCP Server started
```

### 2. Frontend starten

```bash
npm start
```

√ñffne Browser: `http://localhost:4200`

### 3. Admin Panel √∂ffnen

1. Navigiere zu **Admin ‚Üí Sprachassistent**
2. Tab **Modelle & Env**

### 4. Load Test

1. W√§hle eine LLM-Instanz die **nicht geladen** ist (Status: "Nicht geladen üî¥")
2. Klicke auf **Load** Button
3. Backend sollte MCP Request senden:
   ```
   [LoggingService] Attempting to load model {model} via MCP...
   [LmStudioMcpService] (MCP Server logs)
   [LoggingService] Successfully loaded model {model} via MCP
   ```
4. UI sollte zeigen:
   - ‚úÖ "‚úÖ {model} geladen!" (wenn erfolgreich)
   - ‚ö†Ô∏è "‚ö†Ô∏è {model} als aktiv markiert (LM Studio load API nicht verf√ºgbar...)" (wenn API nicht unterst√ºtzt)
5. Status √§ndert sich zu: "Geladen ‚úÖ"

### 5. Eject Test

1. W√§hle eine LLM-Instanz die **geladen** ist (Status: "Geladen ‚úÖ")
2. Klicke auf **Eject** Button
3. Best√§tige Dialog
4. Backend sollte MCP Request senden:
   ```
   [LoggingService] Attempting to eject model {model} via MCP...
   [LmStudioMcpService] (MCP Server logs)
   [LoggingService] Successfully ejected model {model} via MCP
   ```
5. UI sollte zeigen:
   - ‚úÖ "‚úÖ {model} aus LM Studio entladen!" (wenn erfolgreich)
   - ‚ö†Ô∏è "‚ö†Ô∏è {model} als inaktiv markiert, aber Eject fehlgeschlagen..." (wenn API nicht unterst√ºtzt)
6. Status √§ndert sich zu: "Nicht geladen üî¥"

## Erwartete Logs

### Backend Console

**Load erfolgreich**:
```
[LoggingService] Attempting to load model mistral-7b via MCP...
[LmStudioMcpService] Starting LM Studio MCP Server...
[LoggingService] Successfully loaded model mistral-7b via MCP
[LoggingService] Loaded instance: mistral-7b (health: healthy)
```

**Load fehlgeschlagen (API nicht unterst√ºtzt)**:
```
[LoggingService] Attempting to load model mistral-7b via MCP...
[LoggingService] MCP load failed for mistral-7b: LM Studio does not support load API
[LoggingService] Loaded instance: mistral-7b (health: healthy)
```

**Eject erfolgreich**:
```
[LoggingService] Attempting to eject model mistral-7b via MCP...
[LmStudioMcpService] Unload model result for mistral-7b: {success: true}
[LoggingService] Successfully ejected model mistral-7b via MCP
[LoggingService] Ejected instance: mistral-7b via MCP
```

### Frontend Console

```
Loaded LLM instances: 3
Models from instance LM Studio: ['mistral-7b', 'llama-2-7b']
Unique models: ['llama-2-7b', 'mistral-7b']
```

## MCP Server Debugging

### Manuell starten (f√ºr Debugging)

```bash
cd .specify/mcp-servers
node lm-studio-mcp-server.js
```

Der Server l√§uft im stdio-Modus und erwartet JSON-RPC auf stdin.

### Test Load via JSON-RPC

```bash
echo '{"jsonrpc":"2.0","id":1,"method":"tools/call","params":{"name":"load_model","arguments":{"modelId":"mistral-7b"}}}' | node lm-studio-mcp-server.js
```

### Test Unload via JSON-RPC

```bash
echo '{"jsonrpc":"2.0","id":2,"method":"tools/call","params":{"name":"unload_model","arguments":{"modelId":"mistral-7b"}}}' | node lm-studio-mcp-server.js
```

## Troubleshooting

### Problem: "MCP Server exited with code 1"

**Ursache**: MCP Server konnte nicht gestartet werden

**H√§ufigste Ursachen**:

**1. Path Problem: "Cannot find module"**
```
Error: Cannot find module 'C:\Users\...\backend\nest-app\.specify\mcp-servers\lm-studio-mcp-server.js'
```
**L√∂sung**: Der MCP Server muss im Projekt-Root liegen, nicht in `backend/nest-app`:
- Pr√ºfe: `.specify/mcp-servers/lm-studio-mcp-server.js` existiert im **Projekt-Root**
- Der Pfad im Code ist: `../../.specify/mcp-servers/lm-studio-mcp-server.js` (relativ zu `backend/nest-app`)

**2. Dependencies fehlen**
```bash
cd .specify/mcp-servers
npm install
```

**3. Node.js nicht installiert**
```bash
node --version  # sollte v18+ sein
```

### Problem: "Failed to load model via MCP"

**Ursache**: LM Studio nicht erreichbar oder Modell-ID falsch

**L√∂sung**:
1. Pr√ºfe ob LM Studio l√§uft: `http://192.168.56.1:1234`
2. Pr√ºfe Modell-ID in der Instanz-Karte
3. Pr√ºfe LM_STUDIO_URL in `.env`: `LM_STUDIO_URL=http://192.168.56.1:1234`

### Problem: "LM Studio does not support load API"

**Ursache**: LM Studio Version unterst√ºtzt keine Load/Unload APIs

**L√∂sung**:
1. Lade Modell **manuell** in LM Studio UI
2. Klicke dann auf "Load" in der App (markiert als aktiv)
3. Oder: Update LM Studio auf neuere Version

### Problem: Model bleibt auf "Nicht geladen" nach Load

**Ursache**: Load war erfolgreich, aber Health-Check schl√§gt fehl

**L√∂sung**:
1. Pr√ºfe ob Modell in LM Studio UI tats√§chlich geladen ist
2. Klicke auf "Test" Button um Verbindung zu pr√ºfen
3. Pr√ºfe URL der Instanz (muss `/v1/chat/completions` enthalten)

## Network Inspector (Chrome DevTools)

### Load Request

**Request**:
```
POST http://localhost:3001/api/llm-instances/{id}/load
Content-Type: application/json
Body: {}
```

**Response (Success)**:
```json
{
  "_id": "...",
  "name": "LM Studio",
  "model": "mistral-7b",
  "isActive": true,
  "health": "healthy",
  "loadResult": {
    "success": true,
    "message": "Model loaded successfully via MCP",
    "data": {...}
  }
}
```

**Response (API nicht unterst√ºtzt)**:
```json
{
  "_id": "...",
  "model": "mistral-7b",
  "isActive": true,
  "health": "healthy",
  "loadResult": {
    "success": false,
    "error": "LM Studio does not support load API"
  }
}
```

### Eject Request

**Request**:
```
POST http://localhost:3001/api/llm-instances/{id}/eject
Content-Type: application/json
Body: {}
```

**Response**:
```json
{
  "_id": "...",
  "model": "mistral-7b",
  "isActive": false,
  "health": "unknown",
  "ejectResult": {
    "success": true,
    "message": "Model ejected successfully via MCP"
  }
}
```

## Next Steps

Nach erfolgreichem Test:
- [ ] Teste mit verschiedenen Modellen
- [ ] Teste Load/Eject mehrmals hintereinander
- [ ] Teste mit mehreren Instanzen parallel
- [ ] Pr√ºfe ob Modell tats√§chlich in LM Studio geladen/entladen wird
- [ ] Teste Fallback-Szenario (LM Studio gestoppt w√§hrend Load/Eject)

## Performance Notes

- Load/Eject dauert je nach Modell-Gr√∂√üe 5-30 Sekunden
- MCP Server hat 30 Sekunden Timeout
- Health-Check hat 5 Sekunden Timeout
- Bei Timeout: Model wird trotzdem als aktiv/inaktiv markiert

