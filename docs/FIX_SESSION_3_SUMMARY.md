# Fix Session 3: Multi-Active, Instanz-spezifische Prompts & Eject-Dialog âœ…

## Status: VollstÃ¤ndig implementiert

---

## Behobene Probleme (Session 3)

### 1. âœ… Multi-Active Support - Aktivieren deaktiviert keine anderen mehr
**Problem**: Beim Aktivieren einer Instanz wurden alle anderen automatisch deaktiviert â†’ kein Fallback mÃ¶glich

**LÃ¶sung**:
- Backend: Entfernt `updateMany({}, { isActive: false })` aus `activateLlmInstance()`
- Jetzt kÃ¶nnen mehrere Instanzen parallel aktiv sein
- NÃ¼tzlich fÃ¼r Fallback-Szenarien und Load-Balancing

**GeÃ¤ndert**:
- `backend/nest-app/src/modules/logging/logging.service.ts`
  - `activateLlmInstance()` - Multi-Active Support

### 2. âœ… Deaktivieren mit BestÃ¤tigungs-Dialog (Eject)
**Problem**: Deaktivieren-Button hatte keine BestÃ¤tigung, Button-Text unklar

**LÃ¶sung**:
- Frontend: `confirm()` Dialog vor Deaktivierung
- Text: "MÃ¶chten Sie die LLM-Instanz '...' wirklich deaktivieren (eject)?"
- Klarere Begriffe: "eject" = entladen, nicht lÃ¶schen
- Neue Methode `deleteLlmInstance()` fÃ¼r permanentes LÃ¶schen (Backend)

**GeÃ¤ndert**:
- `src/app/features/admin/speech-assistant/admin-speech-assistant.component.ts`
  - `deactivateLlmInstance()` mit BestÃ¤tigungs-Dialog
- `backend/nest-app/src/modules/logging/logging.service.ts`
  - `deactivateLlmInstance()` - setzt `isActive: false`, `health: 'unknown'`
  - `deleteLlmInstance()` - lÃ¶scht Instanz permanent (neuer Endpoint)
- `backend/nest-app/src/modules/logging/logging.controller.ts`
  - `@Post('/llm-instances/:id/delete')` - neuer Endpoint

### 3. âœ… System-Prompt instanz-spezifisch laden & speichern
**Problem**: System-Prompt Textarea blieb leer, keine Instanz-spezifische Verwaltung

**LÃ¶sung**:
- **Card-Klick-System**: Klick auf "Prompt laden"-Button lÃ¤dt den Prompt dieser Instanz
- **Visuelle Markierung**: AusgewÃ¤hlte Card wird blau umrandet (`.selected` CSS-Klasse)
- **Speichern**: Speichert Prompt fÃ¼r aktuell ausgewÃ¤hlte Instanz (nicht nur aktive)
- **Feedback**: Snackbar zeigt fÃ¼r welche Instanz gespeichert wurde

**Neue Methoden**:
- `loadSystemPromptForInstance(instance)` - LÃ¤dt Prompt einer bestimmten Instanz
- `saveSystemPrompt()` - Speichert fÃ¼r `activeInstance` (ausgewÃ¤hlte Card)

**GeÃ¤ndert**:
- `src/app/features/admin/speech-assistant/admin-speech-assistant.component.ts`
  - `loadSystemPromptForInstance()` - neue Methode
  - `loadLlmInstances()` - vereinfacht, ohne auto-save
  - `saveSystemPrompt()` - zeigt Instanz-Name im Feedback
- `src/app/features/admin/speech-assistant/admin-speech-assistant.component.html`
  - "Prompt laden"-Button in jeder Card
  - Card bekommt `[class.selected]` basierend auf `activeInstance._id`
  - Zeigt Instanz-Model statt Name
- `src/app/features/admin/speech-assistant/admin-speech-assistant.component.scss`
  - `.selected` CSS-Klasse (blauer Rahmen)
  - `cursor: pointer` auf Cards

---

## Neue Features

### ğŸ†• Instanz-Prompt-Verwaltung

**Workflow**:
1. User klickt "Prompt laden" Button bei einer Instanz-Card
2. Card wird blau umrandet (selected)
3. Textarea zeigt den Prompt dieser Instanz
4. User bearbeitet Prompt
5. Klickt "System-Prompt speichern"
6. Snackbar: "System-Prompt fÃ¼r [model-name] gespeichert"

**Vorteile**:
- Jede Instanz kann eigenen Prompt haben
- Klar sichtbar welche Instanz gerade bearbeitet wird
- Speichern nur fÃ¼r ausgewÃ¤hlte Instanz (nicht versehentlich fÃ¼r andere)

### ğŸ†• Multi-Active LLM Support

**Use-Cases**:
- **Fallback**: PrimÃ¤res Modell + Fallback-Modell beide aktiv
- **Specialized**: Verschiedene Modelle fÃ¼r verschiedene Tasks
- **Load-Balancing**: Verteilung auf mehrere Instanzen

**Beispiel**:
```
âœ… qwen2.5-0.5b-instruct (aktiv) - schnell fÃ¼r einfache Queries
âœ… mistralai/mistral-7b (aktiv) - fÃ¼r komplexe Reasoning
âŒ llama-3.1-8b (inaktiv) - Reserve
```

### ğŸ†• Eject vs. Delete

**Eject (Deaktivieren)**:
- Setzt `isActive: false`
- Instanz bleibt in DB
- Kann wieder aktiviert werden
- BestÃ¤tigungs-Dialog: "wirklich deaktivieren (eject)?"

**Delete (LÃ¶schen)**:
- LÃ¶scht Instanz permanent aus DB
- Nur via API verfÃ¼gbar: `POST /api/llm-instances/:id/delete`
- Wird spÃ¤ter im UI als eigener Button hinzugefÃ¼gt

---

## API-Ã„nderungen

### POST /api/llm-instances/:id/activate
**Vorher**: Deaktivierte alle anderen Instanzen  
**Jetzt**: Aktiviert nur die angegebene Instanz (Multi-Active)

### POST /api/llm-instances/:id/deactivate
**Neu**: Deaktiviert (eject) eine Instanz, setzt `health: 'unknown'`

### POST /api/llm-instances/:id/delete
**Neu**: LÃ¶scht Instanz permanent aus DB

### GET /api/llm-instances/:id/system-prompt
**UnverÃ¤ndert**: Gibt System-Prompt der Instanz zurÃ¼ck

### PUT /api/llm-instances/:id/system-prompt
**UnverÃ¤ndert**: Speichert System-Prompt fÃ¼r Instanz

---

## UI-Verbesserungen

### Instance-Cards

**Vorher**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LM Studio @ 192...     â”‚
â”‚ URL: http://...        â”‚
â”‚ Model: mistral...      â”‚
â”‚ [Test] [Aktiv]         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Jetzt**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â† Blauer Rahmen wenn selected
â”‚ mistralai/mistral-7b   â”‚ â† Model-Name prominent
â”‚ URL: http://...        â”‚
â”‚ Status: Aktiv          â”‚ â† Klarere Kennzeichnung
â”‚ [Prompt] [Test] [Deak] â”‚ â† Prompt-laden Button
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Status-Anzeige

- **GrÃ¼ner Rahmen** = Aktive Instanz (`isActive: true`)
- **Blauer Rahmen** = AusgewÃ¤hlte Instanz (Prompt geladen)
- **Grauer Rahmen** = Inaktive Instanz

### Buttons

- **"Prompt laden"** - LÃ¤dt System-Prompt dieser Instanz
- **"Test"** - Testet Verbindung
- **"Aktivieren"** (grÃ¼n) - Aktiviert Instanz (nur bei inaktiven)
- **"Deaktivieren"** (rot) - Eject mit BestÃ¤tigungs-Dialog (nur bei aktiven)

---

## Testing

### Test 1: Multi-Active
```typescript
// Aktiviere mehrere Instanzen nacheinander
await activateLlmInstance(instance1);
await activateLlmInstance(instance2);

// Erwartung: Beide sind aktiv
console.log(instance1.isActive); // true
console.log(instance2.isActive); // true
```

### Test 2: Instanz-spezifischer Prompt
```typescript
// 1. Klicke "Prompt laden" bei Instanz A
await loadSystemPromptForInstance(instanceA);
// Card A wird blau, Textarea zeigt Prompt A

// 2. Bearbeite Prompt
this.systemPrompt = "Neuer Prompt fÃ¼r A";

// 3. Speichere
await saveSystemPrompt();
// Snackbar: "System-Prompt fÃ¼r [modelA] gespeichert"

// 4. Klicke "Prompt laden" bei Instanz B
await loadSystemPromptForInstance(instanceB);
// Card B wird blau, Card A nicht mehr
// Textarea zeigt Prompt B (Ã„nderung an A war gespeichert)
```

### Test 3: Eject mit Dialog
```typescript
// Klicke "Deaktivieren" bei aktiver Instanz
await deactivateLlmInstance(instance);

// Erwartung:
// 1. Confirm-Dialog erscheint
// 2. Bei "Abbrechen": nichts passiert
// 3. Bei "OK": Instanz wird deaktiviert, Snackbar erscheint
```

---

## Bekannte EinschrÃ¤nkungen

1. **Delete-Button fehlt im UI**: Permanentes LÃ¶schen nur via API
   - TODO: "LÃ¶schen"-Button mit stÃ¤rkerem BestÃ¤tigungs-Dialog hinzufÃ¼gen

2. **Fallback-Logik**: Backend nutzt noch nicht automatisch Fallback bei Multi-Active
   - TODO: LLM-Anfrage automatisch auf nÃ¤chste aktive Instanz ausweichen bei Fehler

3. **Load-Balancing**: Keine automatische Verteilung bei Multi-Active
   - TODO: Round-Robin oder Least-Loaded Strategie implementieren

---

## Dateien geÃ¤ndert (Session 3)

### Backend
- `backend/nest-app/src/modules/logging/logging.service.ts`
  - `activateLlmInstance()` - Multi-Active Support
  - `deactivateLlmInstance()` - neue Methode
  - `deleteLlmInstance()` - neue Methode
  
- `backend/nest-app/src/modules/logging/logging.controller.ts`
  - `@Post('/llm-instances/:id/deactivate')` - neuer Endpoint
  - `@Post('/llm-instances/:id/delete')` - neuer Endpoint

### Frontend
- `src/app/features/admin/speech-assistant/admin-speech-assistant.component.ts`
  - `loadSystemPromptForInstance()` - neue Methode
  - `deactivateLlmInstance()` - mit BestÃ¤tigungs-Dialog
  - `loadLlmInstances()` - vereinfacht
  - `saveSystemPrompt()` - besseres Feedback
  
- `src/app/features/admin/speech-assistant/admin-speech-assistant.component.html`
  - "Prompt laden"-Button in Cards
  - `[class.selected]` Binding
  - Model-Name statt Instanz-Name
  
- `src/app/features/admin/speech-assistant/admin-speech-assistant.component.scss`
  - `.selected` CSS-Klasse
  - Hover-Effekte

- `src/app/core/services/llm.service.ts`
  - `delete()` - neue Methode

---

## Zusammenfassung

ğŸ‰ **Alle Probleme aus Session 3 behoben!**

âœ… Multi-Active Support - mehrere Instanzen parallel aktiv  
âœ… Deaktivieren mit BestÃ¤tigungs-Dialog (Eject)  
âœ… System-Prompt instanz-spezifisch laden & speichern  
âœ… Visuelle Markierung der ausgewÃ¤hlten Instanz  
âœ… Klarere UI mit Model-Namen und Status  

**NÃ¤chster Schritt**: 
1. Backend starten: `cd backend/nest-app && npm run start:dev`
2. Frontend starten: `npm start`
3. UI testen:
   - Mehrere Instanzen aktivieren (alle bleiben aktiv)
   - "Prompt laden" klicken â†’ Card wird blau
   - Prompt bearbeiten & speichern
   - "Deaktivieren" klicken â†’ Dialog erscheint

ğŸš€ **Implementierung vollstÃ¤ndig!**

